---
title: "EcoTox - ToMEx 2"
author: "Scott Coffin"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    theme: journal
    toc: yes
    toc_float: yes
    toc_depth: 6
    number_sections: true
  word_document:
    toc: yes
---
#Setup
```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=8, fig.path='output/figures',
                      warning=FALSE, message=FALSE,time_it = TRUE) #report
```

## Libraries
```{r Libraries, include = FALSE}
library(tidyverse)
library(calecopal)
library(ssdtools)
library(DT)
library(plotly)
library(gridExtra)
library(grid)
library(wesanderson)
library(ggdark)
library(broom)
library(knitr)
library(kableExtra)
library(viridis)
library(ggrepel)
library(scales)
library(gt)
library(ggsci)
library(openxlsx)
library(ggpubr)

```

```{r Set Particle Size, include = FALSE}
###define sizes for filtering and alignment##
# smaller size bin
small_tier_lower_size <- 1 #um
small_tier_upper_size <- 5000 #um #size to align to
upper.tissue.trans.size.um <- 83 #um #set size for filtering data and x2M
# larger size bin
large_tier_lower_size <- 1 #um
large_tier_upper_size <- 5000 #um
```

```{r Aesthetics, include = FALSE}
#Theme
theme.type <- dark_theme_bw(base_size = 15) +
  #theme_bw(base_size = 15) +
              theme(plot.title = element_text(hjust = 0.5),
                    plot.subtitle = element_text(hjust = 0.5))

#Fill
fill.type <-  scale_fill_nejm()

#Color
color.type <- scale_color_nejm()
```

```{r Data Import, include = FALSE}
#Load aoc_z into dataframe. This file is generated from aq_mp_tox_shiny repo / ToMEx2.0_Onboarding / ToMEx2.0_Data_Tidying.R

aoc_z <- readRDS(file = "data/input/aoc_z_tomex2.RDS") %>% 
  #rename columns so they fir the OG script
  rename(environment = env_f)
```

#Framework Summary

![Agreed-upon framework](www/Treshold_Framework.png)

The figure above displays the working threshold framework for the ambient threshold group for the Microplastics Health Effects Workshop. 

The current framework for generating SSDs includes the following parameters:

Data pertaining to only aquatic organisms are included (marine and freshwater).  

All taxa are included with the exception of bacterium and plants.  

HONEC (Highest Observed No Effect Concentration) are excluded.  

Assessment factors are applied to convert all other effect metrics into NOECs:

![](www/AF_EM.png)

Reference: Wigger et al. 2020 (doi: 10.1002/ieam.4214)  

Assessment factors are applied to convert acute data into chronic:  

![](www/AF_chronic.png)

Green rows are from Wigger et al. 2020. Grey rows were agreed upon by the ambient threshold working group.

Reference: Wigger et al. 2020 (doi: 10.1002/ieam.4214)

Note: Values may be slightly different than those presented in the shiny app as concentrations are converted from particles/mL to particles/L ahead of calculations.


# ERM/SSD Calculations
The following script utilizes the above equations to calculate *a priori* effect thresholds for each of the ERM of interest for each species in the database, then calculates species sensitivity distributions using each ERM.

*Data Filtering by Quality*
```{r}
## First filter data with global filters
aoc_intermediate <- aoc_z %>% 
  filter(!environment %in% c("Terrestrial", "Not Reported"),
         Group != "Bacterium",
         Group != "Plant",
         effect.metric != "HONEC",
         tier_zero_tech_f == "Red Criteria Passed",
         tier_zero_risk_f == "Red Criteria Passed", #All thresholds must pass technical and risk red criteria
         risk.13 != 0 #Drop studies that received a score of 0 for endpoints criteria (this also drops studies that have not yet been scored) - KEEP THIS AFTER THE RED CRITERIA FILTERS  
         ) %>% 
  #Remove 26C temperature treatment data from Jaimukar et al. 2018
  filter(!(article == 42 & media.temp == 26)) %>% 
  mutate(max.size.ingest.um = 1000 * max.size.ingest.mm) #makes it less confusing below
#### Ecologically Relevant Metric calculations ####

#examine available data as histogram
Group_size <- aoc_intermediate %>% 
  ggplot(aes(x = size.length.um.used.for.conversions, fill = Group)) +
  geom_histogram(bins = 25) +
  scale_fill_manual(values = cal_palette(name = "superbloom1", type = "continuous", n = 11)) +
  labs(title = "Filtered Data by Group") +
  ylab("# of observations")+
  xlab("Length (um)") +
  theme.type +
  scale_x_log10()

endpoint_size <- aoc_intermediate %>% 
  ggplot(aes(x = size.length.um.used.for.conversions, fill = lvl1_f)) +
  geom_histogram(bins = 25) +
   scale_fill_manual(name = "General Endpoint", values = cal_palette(name = "superbloom3", type = "continuous", n = 11)) +
  xlab("Particle Length (um)") +
  ylab("# of observations")+
  labs(title = "Filtered Data by General Endpoint") +
  theme.type +
  scale_x_log10()

#arrange histograms
grid.arrange(Group_size, endpoint_size)
```

### Alignment

#### Parameters
```{r}
## parametrization ##
# Define params for correction #
alpha = 2.07 #table s4 for marine surface water. length
# define parameters for power law coefficients
a.sa = 1.5 #marine surface area power law
a.v = 1.48 #a_V for marine surface water volume
a.m = 1.32 # upper limit fora_m for mass for marine surface water in table S4 
a.ssa = 1.98 # A_SSA for marine surface water

#define additional parameters for calculations based on averages in the environment
R.ave = 0.77 #average width to length ratio for microplastics in marine enviornment
p.ave = 1.10 #average density in marine surface water

#join alpha values for each data point
aoc_intermediate_alphas <- aoc_intermediate %>% 
  mutate(alpha = alpha) %>% 
  mutate(a.sa = a.sa) %>% 
   mutate(a.v =  a.v) %>% 
   mutate(a.m =  a.m) %>% 
   mutate(a.ssa = a.ssa) %>% 
   mutate(R.ave = R.ave) %>% 
   mutate(p.ave = p.ave)
```

#### Functions
```{r}
###function to derive correction factor (CF) from Koelmans et al (equation 2)
CFfnx = function(a, #default alpha from Koelmans et al (2020)
                 x2D, #set detault values to convert ranges to (1-5,000 um) #5mm is upper defuault 
                 x1D, #1 um is lower default size
                 x2M, x1M){
  CF = (x2D^(1-a)-x1D^(1-a))/(x2M^(1-a)-x1M^(1-a)) 
  return(CF)}

#### equations for mu_x_poly (note that there are three depending on certain alphas for limits of equation)
#generalizable if a.x =2 or not
mux.polyfnx_generalizable = Vectorize(function(a.x, x_UL, x_LL){
  if(a.x == 1){ # in case a.x = 1
    mux.poly = (x_UL - x_LL)/(log(x_UL/x_LL))
    return(mux.poly)}
  if(a.x == 2){ # in case a.x = 2
     mux.poly = (log10(x_UL/x_LL))/(x_LL^(-1) - x_UL^-1)
     return(mux.poly)}
  else{ #in case alpha is not 2 or 1
    mux.poly = ((1-a.x)/(2-a.x)) * ((x_UL^(2-a.x) - x_LL^(2-a.x))/(x_UL^(1-a.x) - x_LL^(1-a.x)))
    return(mux.poly)}
  },
  vectorize.args = "a.x") # if Vectorize isn't here, the if else won't work
## ^^ Note that the above generalizable function doesn't play well with mutate(case_when), likely due to some bug with dplyr. I don't have a solution to this, so a special equation will need to be used when those values are used...

#in case alpha is not 1 or 2
mux.polyfnx = function(a.x, x_UL, x_LL){
    mux.poly = ((1-a.x)/(2-a.x)) * ((x_UL^(2-a.x) - x_LL^(2-a.x))/(x_UL^(1-a.x) - x_LL^(1-a.x)))
    return(mux.poly)}

##### If alpha does equal 2 #####
mux.polyfnx2 = function(a.x, x_UL,x_LL){
  mux.poly = (log(x_UL/x_LL))/(x_LL^(-1) - x_UL^-1)
  return(mux.poly)}

##### If alpha equals 1 #####
mux.polyfnx1 = function(a.x, x_UL, x_LL){
     mux.poly = (x_UL - x_LL)/(log(x_UL/x_LL)) #natural log
    return(mux.poly)}

### Calculating max ingestible parameters ###
## function to calcualte min and max ingestible surface area ##
SAfnx = function(a, # a = 0.5 * length
                 b, # b = 0.5 * width
                 c # c = 0.5 * height (note that hieght is 0.67 * width)
){
  SA = 4*pi*(((a*b)^1.6 + (a*c)^1.6 + (b*c)^1.6) / 3)^(1/1.6)
  return(SA)}

## max ingestible volume ##

volumefnx = function(R, L){
  volume = 0.111667 * pi * R^2 * L^3 #assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
  return(volume)}

volumefnx_poly = function(width, length){
  height = 0.67 * width
  volume = (4/3) * pi * (length/2) * (width/2) * (height/2) #assumes height = 0.67 * Width 
  return(volume)}

#max ingestible mass (only used for mu_mono calculations)
massfnx = function(R, L, p){
  mass = p * #density (g/cm^3)
    0.111667 * pi * R^2 * L^3 * # volume (um^3): assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
    1/1e12 * 1e6 #correction factor
  return(mass)}

massfnx_poly = function(width, length, p){
  height = 0.67 * width
  volume = (4/3) * pi * (length/2) * (width/2) * (height/2) #assumes height = 0.67 * Width 
  mass = p * #density (g/cm^3)
    volume * # volume (um^3): assumes height = 0.67 * Width, and Width:Length ratio is 'R' (compartment-specific)
    1/1e12 * 1e6 #correction factor
  return(mass)}

#max ingestible specific surface area
SSAfnx = function(sa, #surface area, calcaulted elsewhere
                  m){ #mass, calculated elsewhere
  SSA = sa/m
    return(SSA)}

#max ingestible specific surface area
SSA.inversefnx = function(sa, #surface area, calcaulted elsewhere
                  m){ #mass, calculated elsewhere
  SSA.inverse = m / sa
    return(SSA.inverse)}
```

#### Calculate

Here we will calculate two aligned exposure concentrations: surface area (1 - 83 um), and volume (1 - 5,000 um). For both, the upper aligned value is the smaller of either the nominal size listed or the mouth size of the species.

```{r}
###define sizes for alignment##
x1M_set <- 1 #um lower size for all alignments
x1D_set <- 1 #um lower size for all alignments
x2D_set <- 5000 #um
upper.tissue.trans.size.um <- 83 #10 #um #set size for x2M

# calculate ERM for each species
aoc_final <- aoc_intermediate_alphas  %>% 
   #### TISSUE TRANSLOCATION ####
# define upper size length for Translocation 
#set to 83um for upper limit or max size ingest, whichever is smaller
mutate(x2M_trans = case_when(is.na(max.size.ingest.um) ~ upper.tissue.trans.size.um, 
                             max.size.ingest.um  < upper.tissue.trans.size.um ~  max.size.ingest.um,
                             max.size.ingest.um  > upper.tissue.trans.size.um ~ upper.tissue.trans.size.um)) %>% 
  
 # calculate effect threshold for particles
  mutate(EC_mono_p.particles.mL_trans = dose.particles.mL.master) %>% 
  mutate(mu.p.mono = 1) %>% #mu_x_mono is always 1 for particles to particles
  mutate(mu.p.poly_trans = mux.polyfnx(a.x = alpha, #alpha for particles
                                 x_UL= x2M_trans, #upper ingestible size limit (width of particle)
                                 x_LL = x1M_set)) %>% 
  # polydisperse effect threshold for particles
  mutate(EC_poly_p.particles.mL_trans = (EC_mono_p.particles.mL_trans * mu.p.mono)/mu.p.poly_trans) %>% 
   #calculate CF_bio for all conversions
  mutate(CF_bio_trans = CFfnx(x1M = x1M_set,#lower size bin
                        x2M = x2M_trans, #upper translocatable
                        x1D = x1D_set, #default
                        x2D = x2D_set,  #default
                        a = alpha)) %>%  
  ## Calculate environmentally relevant effect threshold for particles
  mutate(EC_env_p.particles.mL_trans = EC_poly_p.particles.mL_trans * CF_bio_trans) %>%  #aligned particle effect concentraiton (1-5000 um)
  
  #### Surface area ERM ####
##--- environmental calculations ---###
  #calculate lower translocatable surface area
  mutate(x_LL_sa_trans = SAfnx(a = 0.5 * x1D_set, #length
                               b = 0.5 * x1D_set, #0.5 * R.ave * x1D_set, #width
                               c = 0.5 * x1D_set  #0.5 * R.ave * 0.67 * x1D_set #height
                               )) %>%  
  #calculate upper translocatable surface area
  mutate(x_UL_sa_trans = SAfnx(a = 0.5 * x2M_trans, 
                               b = 0.5 * x2M_trans, #width #0.5 * R.ave * x2M, 
                               c = 0.5 * x2M_trans #heigth #0.5 * R.ave * 0.67 * x2M
                               )) %>%  
  #calculate mu_x_poly (env) for surface area
  mutate(mu.sa.poly_trans = mux.polyfnx(a.sa, x_UL_sa_trans, x_LL_sa_trans)) %>% 
  
  ##--- laboratory calculations ---###
  ## define mu_x_mono OR mu_x_poly (lab) for alignment to ERM  #
  #(note that if mixed particles were used, a different equation must be used)
  mutate(mu.sa.mono = case_when(
    polydispersity == "monodisperse" ~ particle.surface.area.um2, # use reported surface area in monodisperse
    polydispersity == "polydisperse" ~  mux.polyfnx(a.x = a.sa, 
                                  x_LL = particle.surface.area.um2.min,
                                  x_UL = particle.surface.area.um2.max))) %>% 
  
   #calculate polydisperse effect concentration for surface area (particles/mL)
  mutate(EC_poly_sa.particles.mL_trans = (EC_mono_p.particles.mL_trans * mu.sa.mono)/mu.sa.poly_trans) %>%  
  #calculate environmentally realistic effect threshold
  mutate(EC_env_sa.particles.mL_trans = EC_poly_sa.particles.mL_trans * CF_bio_trans) %>% 
  
  ##### FOOD DILUTION ####
  # define upper size length for ingestion 
  mutate(x2M_ingest = case_when(is.na(max.size.ingest.um) ~ x2D_set, 
                         max.size.ingest.um < x2D_set ~ max.size.ingest.um,
                         max.size.ingest.um > x2D_set ~ x2D_set
                         )) %>%  #set to 5,000 as upper limit or max size ingest, whichever is smaller
 # calculate effect threshold for particles
  mutate(EC_mono_p.particles.mL_ingest = dose.particles.mL.master) %>% 
  mutate(mu.p.mono = 1) %>% #mu_x_mono is always 1 for particles to particles
  mutate(mu.p.poly_ingest = mux.polyfnx(a.x = alpha, #alpha for particles
                                 x_UL= x2M_ingest, #upper ingestible size limit
                                 x_LL = x1M_set)) %>% 
  # polydisperse effect threshold for particles
  mutate(EC_poly_p.particles.mL_ingest = (EC_mono_p.particles.mL_ingest * mu.p.mono)/mu.p.poly_ingest) %>% 
   #calculate CF_bio for all conversions
  mutate(CF_bio_ingest = CFfnx(x1M = x1M_set,#lower size bin
                        x2M = x2M_ingest, #upper ingestible length
                        x1D = x1D_set, #default
                        x2D = x2D_set,  #default upper size range
                        a = alpha)) %>%  
  ## Calculate environmentally relevant effect threshold for particles
  mutate(EC_env_p.particles.mL_ingest = EC_poly_p.particles.mL_ingest * CF_bio_ingest) %>%  #aligned particle effect concentraiton (1-5000 um)
  
  
  #### volume ERM ####
##--- environmental calculations ---###
  #calculate lower ingestible volume 
  mutate(x_LL_v_ingest = volumefnx_poly(length = x1D_set,
                                 width = x1D_set)) %>% 
  #calculate maximum ingestible volume 
  mutate(x_UL_v_ingest = volumefnx_poly(length = x2M_ingest, # length-limited
                                 #x2D_set, #upper definiton (accouunts for fibers) CONSERVATIVE
                                 width = x2M_ingest)) %>% #ingestion-limited
  # calculate mu.v.poly
  mutate(mu.v.poly_ingest = mux.polyfnx(a.v, x_UL_v_ingest, x_LL_v_ingest)) %>% 
  ##--- laboratory calculations ---###
  ## define mu_x_mono OR mu_x_poly (lab) for alignment to ERM  #
  #(note that if mixed particles were used, a different equation must be used)
  mutate(mu.v.mono = case_when(
    polydispersity == "monodisperse" ~ particle.volume.um3, # use reported volume in monodisperse
    polydispersity == "polydisperse" ~ mux.polyfnx(a.x = a.v, 
                                                   x_LL = particle.volume.um3.min,
                                                   x_UL = particle.volume.um3.max))) %>% 
  
  #calculate polydisperse effect concentration for volume (particles/mL)
  mutate(EC_poly_v.particles.mL_ingest = (EC_mono_p.particles.mL_ingest * mu.v.mono)/mu.v.poly_ingest) %>%  
    #calculate environmentally realistic effect threshold
  mutate(EC_env_v.particles.mL_ingest = EC_poly_v.particles.mL_ingest * CF_bio_ingest) %>% 
  
   ###### CLEANUP #####
  mutate(particles.mL.ox.stress = EC_env_sa.particles.mL_trans,
         particles.mL.food.dilution = EC_env_v.particles.mL_ingest)
```

###### Save Aligned dataset
```{r}
saveRDS(aoc_final,"data/output/aoc_final.RDS")
```


####Test to see if same thresholds attained in main risk calculation
##### SSD Functions
```{r}
#### define function for SSD generation for tier 1 ####
SSD_function_t1 <- function(filtered.data, hcxlcl){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.25))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE, 
                 #ic = "aicc",
                 nboot = 10, ci= TRUE) 
#report HC metrics of interest
hc5lcl <- c(preds$lcl[hcxlcl]) #CI95
#values to extract
print(hc5lcl)
}

# Leave-one-out by study function
sensitivity_t1 <- Vectorize(function(x, y) {
  train <- filtered.data[!filtered.data$doi %in% x,]
   SSD_function_t1(train, hcxlcl = y)
})

#### define function for SSD generation for tier 2 ####
SSD_function_t2 <- function(filtered.data, hcx){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.25))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE,# ic = "aicc",
                 nboot = 10, ci= TRUE) 
#report HC metrics of interest
hc <- c(preds$est[hcx]) #HC5
#values to extract
#print(hc5)
print(hc)
}

#### define function for SSD generation for tiers 3 and 4 ####
SSD_function_t3_4 <- function(filtered.data, hcx){
  set.seed(99)
  #data collapse
collapsed <- filtered.data %>% 
  #filter specific things for tiers 3 and 4
   filter(risk.13 != 1,
         bio_f %in% c("Organism", "Population")) %>% 
  group_by(Species, Group) %>% 
  summarize(Conc = quantile(dose_new, 0.50))
#fit distributions
dists <- ssd_fit_dists(collapsed, left = "Conc", dists = c("weibull", "llogis", "lnorm", "gamma", "lgumbel"), computable = FALSE, silent = FALSE) 
#use average distribution with weighthing based on AICC
preds <- predict(dists, average = TRUE, 
                 #ic = "aicc", 
                 nboot = 10, ci= TRUE) 
#report HC metrics of interest
hc <- c(preds$est[hcx]) #HC5
#values to extract
#print(hc5)
print(hc)
}
```


##### Base Thresholds
```{r}
#filter out risk criteria (not done above)#
aoc_risk_paper <- aoc_final %>% 
  drop_na(effect.metric) %>% 
   filter(
     tier_zero_tech_f == ("Red Criteria Passed"))

####---- TISSUE TRANSLOCATION ------#####
filtered.data.small.default_t1.2 <- aoc_risk_paper %>% 
          mutate(dose_new = particles.mL.ox.stress / (af.time * af.noec)) %>%  
         drop_na(dose_new) %>% 
         mutate(dose_new = dose_new * 1000) %>% 
  filter(between(size.length.um.used.for.conversions, 1, upper.tissue.trans.size.um),
         shape_f != "Not Reported",
         poly_f != "Not Reported",
         !environment %in% c("Terrestrial", "Not Reported"),
         Group != "Bacterium",
         Group != "Plant",
         effect.metric != "HONEC")

filtered.data.small.default_t3.4 <- filtered.data.small.default_t1.2 %>% 
 filter(risk.13 != 1,
         bio_f %in% c("Organism", "Population"))

# get thresholds
small.default.t1 <- SSD_function_t1(filtered.data = filtered.data.small.default_t1.2, hcxlcl = 5)
small.default.t2 <- SSD_function_t2(filtered.data = filtered.data.small.default_t1.2, hcx = 5)
small.default.t3 <- SSD_function_t3_4(filtered.data = filtered.data.small.default_t3.4, hcx = 5)
small.default.t4 <- SSD_function_t3_4(filtered.data = filtered.data.small.default_t3.4, hcx = 10)

####---- Food Dilution ------#####
filtered.data.large.default_t1.2 <- aoc_risk_paper %>% 
   # remove algae, as food dilution MOE doesn't make sense for algae
  filter(Group != "Algae") %>% 
         mutate(dose_new = particles.mL.food.dilution / (af.time * af.noec)) %>%  
         drop_na(dose_new) %>% 
         mutate(dose_new = dose_new * 1000) %>% 
  filter(between(size.length.um.used.for.conversions, x1D_set, x2D_set),
         poly_f != "Not Reported",
         !environment %in% c("Terrestrial", "Not Reported"),
         Group != "Bacterium",
         Group != "Plant",
         effect.metric != "HONEC")

filtered.data.large.default_t3.4 <- filtered.data.large.default_t1.2 %>% 
 filter(risk.13 != 1,
         bio_f %in% c("Organism", "Population"))

# get thresholds
large.default.t1 <- SSD_function_t1(filtered.data = filtered.data.large.default_t1.2, hcxlcl = 5)
large.default.t2 <- SSD_function_t2(filtered.data = filtered.data.large.default_t1.2, hcx = 5)
large.default.t3 <- SSD_function_t3_4(filtered.data = filtered.data.large.default_t3.4, hcx = 5)
large.default.t4 <- SSD_function_t3_4(filtered.data = filtered.data.large.default_t3.4, hcx = 10)

base_thresholds <- tibble(
  "Tier" = c('Tier1', 'Tier2', 'Tier3', 'Tier4'),
  "Tissue Translocation (Default)" = c(small.default.t1, small.default.t2, small.default.t3, small.default.t4),
  "Food Dilution (Default)" = c(large.default.t1, large.default.t2, large.default.t3, large.default.t4))

base_thresholds
```
# Probabilistic Species Sensitivity Distribution Plus

The below code will not run with an open environment due to memory constraints.
```{r eval=TRUE, include=FALSE}
#library(gdata)
#keep(tier1_2_large, sure = TRUE)
#write.csv(tier1_2_large, "output/tier1_2_large.csv")
#rm(list = ls())
#gc()
#tier1_2_large <- read.csv("output/tier1_2_large.csv")

tier1_2_large <- filtered.data.small.default_t1.2
```

```{r eval=TRUE, include=FALSE}
# -------------------------------------------------------------------------------------------------
# Code based on PSSD and PNEC calculations using the tool PSSD+ developed by Wigger et al. (2019)
# -------------------------------------------------------------------------------------------------
# 
# Associated publication: Systematic consideration of parameter uncertainty and variability in
#                         probabilistic species sensitivity distributions
# 
# Authors: Henning Wigger, Delphine Kawecki, Bernd Nowack and V?ronique Adam
# 
# Institute: Empa, Swiss Federal Laboratories for Materials Science and Technology,
#            Technology and Society Laboratory, Lerchenfeldstrasse 5, 9014 St. Gallen, Switzerland
# 
# submitted to Integrated Environmental Assessment and Management in December 2018
# 
# -------------------------------------------------------------------------------------------------

##### Build functions ####
source("scripts/PSSD/rmore.r")
source("scripts/PSSD/do.pssd.r")
#source("PSSD/do.pssd.troph.r")
#source("PSSD/do.pssd.ag.r")


###################################################################################################
##### MAIN PARAMETERS FOR THE CALCULATION #########################################################
###################################################################################################

# number of simulations for the triangular distributions of the data points and uncertainty factors
SIM <- 10 #10 is minimum, 10,000 is recommended

# coefficient of variation for the data point distributions
CV.DP <- 0.3

# coefficient of variation for the uncertainty factor distributions
CV.UF <- 0.5
```
## Data preparation
```{r eval=TRUE, include=FALSE}
memory.limit(size=56000) #force R to use more memory than what's phyiscally available
library(reshape2)
require(tidyverse)
require(Matrix)

t2 <- tier1_2_large %>% 
  filter(Species == "Daphnia magna")

# prep dataframe for tox datapoints
DP_1_large_volume <-  t2 %>% 
  #mutate(tier = "A") %>% 
  mutate(id = row_number()) %>% 
  mutate(particles_L = EC_env_v.particles.mL_ingest * 1000) %>% #must *10 to eliminate sub-zero values, can't go above 10 b/c R can't handle integers above certain value
  mutate(particles_L_round = as.integer(round(particles_L,digits = 1))) %>%  #must make integer for below code to work
  select(id, Species, particles_L_round) %>% 
  acast(id ~ Species, value.var = "particles_L_round") %>% 
  Matrix(sparse = TRUE) # makes a smaller object than using as.matrix()

#prep uncertainty factors for conversion from acute to chronic values
UFt_1_large_volume <- t2 %>% 
  mutate(id = row_number()) %>% 
  select(id, Species, af.time) %>% 
  acast(id ~ Species, value.var = "af.time")

# uncertainty factors for conversion of dose descriptors to NOEC
UFdd_1_large_volume <- t2 %>% 
  mutate(id = row_number()) %>% 
  select(id, Species, af.noec) %>% 
  acast(id ~ Species, value.var = "af.noec")
#rm(tier1_2_large)
```

## Tier 1_2_Large_volume
```{r eval=TRUE, include=FALSE}
# read toxicity data
# data points from the literature
DP   <- DP_1_large_volume
# uncertainty factors for conversion from acute to chronic values
UFt  <- UFt_1_large_volume
# uncertainty factors for conversion of dose descriptors to NOEC
UFdd <- UFdd_1_large_volume


###################################################################################################
##### CALCULATION OF NOECs and PSSDs ##############################################################
###################################################################################################

# estimate the NOEC distributions for each Species
NOEC_t1_volume <- do.pSSD(DP, UFt, UFdd, SIM, CV.DP, CV.UF)

# calculate the deterministic (modal) values of the NOEC
NOEC.det_t1_volume <- DP/(UFdd*UFt)

###convert to particles/L
NOEC2_t1_volume = NOEC_t1_volume * 1000 #correction factor from getting into integer values (above)
NOEC.det2_t1_volume = NOEC.det_t1_volume * 1000
```

```{r eval=TRUE, include=FALSE}
###################################################################################################
##### EXAMPLES OF RESULTS #########################################################################
###################################################################################################

### Plot the probability densities of some Species

## For a Species with 1 endpoint (T. thermophila)
# histogram
hist(log10(NOEC2_t1_volume[3,]), freq = F, main = "Ceriodaphnia dupia - 14 endpoints", xlab = "NOEC log[particles/L]")
# probability density
lines(density(log10(NOEC2_t1_volume[3,])), col = "red", lwd = 2) 
# Deterministic NOEC
abline(v = median(log10(NOEC.det2_t1_volume[,3]), na.rm = TRUE), col = "green", lty = 2, lwd = 2)
```

```{r eval=TRUE, include=FALSE}
## For a Species with 1 endpoints (Danio rerio)
hist(NOEC_t1_volume[11,], freq = F, main = "Danio rero - 1 endpoints", xlab = "NOEC [ug/l]")
lines(density(NOEC_t1_volume[11,]), col = "red", lwd = 2)
abline(v = median(NOEC.det_t1_volume[,11], na.rm = TRUE), col = "green", lty = 2, lwd = 2)

# for(i in 1:length(which(!is.na(NOEC.det[,11])))){
#   abline(v = NOEC.det[i,11], col = "green", lty = 2, lwd = 2)
#}

```

```{r eval=TRUE, include=FALSE}
### Plot PSSDs

# calculate all PSSD curves
xvalues <- seq(-6,7,0.001)
PSSD <- matrix(NA, SIM, length(xvalues))
# calculate the ecdf function
for(i in 1:SIM){
  the.ecdf.f <- ecdf(log(NOEC_t1_volume[,i], base = 10))
  PSSD[i,] <- the.ecdf.f(xvalues)
}

```

```{r eval=TRUE, include=FALSE}
# Plot the mean PSSD
plot(c(-2,6), c(0,1),
     main = "Microplastics Probabilistic SSD (1-5,000 um; volumetric)",
     xlab = "NOEC [particles/L]",
     ylab = "Proportion of Species Affected",
     type = "n",
     axes = F)
axis(1, at = c(-2,0,2,4,6), labels = expression(10^-2, 10^0, 10^2, 10^4, 10^6), lwd = 0.5)
axis(2, lwd = 0.5, las = 1)
abline(h = seq(0,1,0.2), lty = 1, lwd = 0.5, col = "gray90")
abline(v = seq(-6,5,1), lty = 1, lwd = 0.5, col = "gray90")
box(lwd = 0.5)
lines(xvalues, apply(PSSD,2,function(x) {mean(x)}), col = "red", lwd = 1.5)
legend("topleft", "Mean PSSD", col = "red", lwd = 1.5)
```

## Tier 1_2_Small_SurfaceArea
```{r eval=TRUE, include=FALSE}
t2_s <- tier1_2_small#%>% 
 # filter(Species == "magna")

# prep dataframe for tox datapoints
DP_1_small_surfaceArea <-  t2_s %>% 
  #mutate(tier = "A") %>% 
  mutate(id = row_number()) %>% 
  mutate(particles_L = EC_env_sa.particles.mL * 1000) %>% #must *10 to eliminate sub-zero values, can't go above 10 b/c R can't handle integers above certain value
  mutate(particles_L_round = as.integer(round(particles_L,digits = 1))) %>%  #must make integer for below code to work
  select(id, Species, particles_L_round) %>% 
  acast(id ~ Species, value.var = "particles_L_round") %>% 
  Matrix(sparse = TRUE) # makes a smaller object than using as.matrix()

#prep uncertainty factors for conversion from acute to chronic values
UFt_1_small_surfaceArea <- t2_s %>% 
  mutate(id = row_number()) %>% 
  select(id, Species, af.time) %>% 
  acast(id ~ Species, value.var = "af.time")

# uncertainty factors for conversion of dose descriptors to NOEC
UFdd_1_small_surfaceArea <- t2_s %>% 
  mutate(id = row_number()) %>% 
  select(id, Species, af.noec) %>% 
  acast(id ~ Species, value.var = "af.noec")

# read toxicity data
# data points from the literature
DP   <- DP_1_small_surfaceArea
# uncertainty factors for conversion from acute to chronic values
UFt  <- UFt_1_small_surfaceArea
# uncertainty factors for conversion of dose descriptors to NOEC
UFdd <- UFdd_1_small_surfaceArea


###################################################################################################
##### CALCULATION OF NOECs and PSSDs ##############################################################
###################################################################################################

# estimate the NOEC distributions for each Species
NOEC_t1_SA <- do.pSSD(DP, UFt, UFdd, SIM, CV.DP, CV.UF)

# calculate the deterministic (modal) values of the NOEC
NOEC.det_t1_SA <- DP/(UFdd*UFt)

###convert to particles/L
NOEC2_t1_SA = NOEC_t1_SA * 1000 #correction factor from getting into integer values (above)
NOEC.det2_t1_SA = NOEC.det_t1_SA * 1000
```

## Plotting
```{r eval=TRUE, include=FALSE}
# calculate PNEC (HC5) for volume and surface area
PNEC_t1_SA <- apply(NOEC_t1_SA,2,function(x){quantile(x, probs = 0.05, na.rm = TRUE) })

PNEC_t1_volume <- apply(NOEC_t1_SA,2,function(x){quantile(x, probs = 0.05, na.rm = TRUE) })

#make into dataframe
PNECs <- data.frame( = PNEC_t1_SA,
                    

PNEC %>% 
  data.frame(PNEC) %>% 
  ggplot(aes(x = PNEC))
```

